{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4a2984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "top_5_ryzen_7 = [\n",
      "    \"AMD Ryzen 7 7800X3D\",\n",
      "    \"AMD Ryzen 7 5800X3D\",\n",
      "    \"AMD Ryzen 7 7700X\",\n",
      "    \"AMD Ryzen 7 5700X\",\n",
      "    \"AMD Ryzen 7 5700G\"\n",
      "]\n",
      "```\n",
      "\n",
      "1.7703123092651367\n"
     ]
    }
   ],
   "source": [
    "# Simple LLM prompt \n",
    "\n",
    "import time \n",
    "\n",
    "from vertexai import init \n",
    "\n",
    "from vertexai.generative_models import GenerativeModel, Part, GenerationConfig \n",
    "\n",
    "st = time.time() \n",
    "\n",
    "init(project=\"cjnyasg-customer360\", location=\"us-central1\")  \n",
    "\n",
    "model = GenerativeModel(\"gemini-2.0-flash-001\") \n",
    "\n",
    "prompt = 'Create a list in python format of top 5 AMD ryzen 7 desktop CPU. No explanation is needed.' \n",
    "\n",
    "input_parts = [Part.from_text(prompt)]  \n",
    "\n",
    "generation_config = GenerationConfig(temperature=0, max_output_tokens=8192) \n",
    "\n",
    "response = model.generate_content(contents=input_parts, generation_config=generation_config) \n",
    "\n",
    "response = response.text \n",
    "\n",
    "print(response) \n",
    "\n",
    "print(time.time() - st) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf907d09",
   "metadata": {},
   "source": [
    "Activity 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99dd0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 4.346190929412842\n",
      "{'Description': \"The image shows a brown dachshund dog standing on its hind legs in front of a black electric piano. The dog is wearing a black collar with silver accents. Its front paws are resting on the piano keys, as if it is playing the instrument. Sheet music is placed on the piano's music stand. The background is blurred, but it appears to be an indoor setting with a plant visible behind the piano. The overall impression is humorous, suggesting the dog is a musician or is pretending to play the piano.\"}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from vertexai import init\n",
    "from vertexai.generative_models import GenerativeModel, Part, GenerationConfig\n",
    "\n",
    "def extract(pdf_path: str, page_number: int = 0):\n",
    "    \"\"\"Extract prompt text and the first image from a PDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_number]\n",
    "    prompt_text = page.get_text().strip()\n",
    "\n",
    "    images = page.get_images(full=True)\n",
    "    if not images:\n",
    "        raise ValueError(\"No images found on the specified page.\")\n",
    "    \n",
    "    # Extracts first image from the page\n",
    "    xref = images[0][0]\n",
    "    base_image = doc.extract_image(xref)\n",
    "    image_bytes = base_image[\"image\"]\n",
    "    image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "\n",
    "    return prompt_text, image\n",
    "\n",
    "def describe_image(pdf_path: str, page_number: int = 0):\n",
    "    st = time.time()\n",
    "    init(project=\"cjnyasg-customer360\", location=\"us-central1\")\n",
    "\n",
    "    model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "\n",
    "    prompt_text, image = extract(pdf_path, page_number)\n",
    "\n",
    "    # Convert PIL image to bytes\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    image.save(img_byte_arr, format='PNG')\n",
    "    img_bytes = img_byte_arr.getvalue()\n",
    "\n",
    "    # Create Gemini-compatible Parts\n",
    "    image_part = Part.from_data(data=img_bytes, mime_type=\"image/png\")\n",
    "    prompt_part = Part.from_text(prompt_text)\n",
    "\n",
    "    input_parts = [prompt_part, image_part]\n",
    "\n",
    "    generation_config = GenerationConfig(temperature=0.2, max_output_tokens=1024)\n",
    "\n",
    "    response = model.generate_content(contents=input_parts, generation_config=generation_config)\n",
    "    description = response.text.strip()\n",
    "\n",
    "    result = {\"Description\": description}\n",
    "    print(\"Time elapsed:\", time.time() - st)\n",
    "    print(result)\n",
    "    print(type(result))\n",
    "\n",
    "    return result\n",
    "\n",
    "# === Usage ===\n",
    "if __name__ == \"__main__\":\n",
    "    describe_image(\"C:/Users/richard.c.ferrer/Agents/image_ai.pdf\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf52447",
   "metadata": {},
   "source": [
    "Activity 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50554068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD Ryzen,Intel\n",
      "Ryzen 9 7950X3D,Core i9-14900K\n",
      "Ryzen 7 7700X,Core i7-14700K\n",
      "Ryzen 5 7600X,Core i5-14600K\n",
      "Ryzen 5 5600X,Core i5-13400F\n",
      "Ryzen 3 4100,Core i3-12100F\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/richard.c.ferrer/Agents/cpu_models.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Save to CSV file\u001b[39;00m\n\u001b[32m     33\u001b[39m csv_filename = \u001b[33m\"\u001b[39m\u001b[33mC:/Users/richard.c.ferrer/Agents/cpu_models.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[32m     35\u001b[39m     writer = csv.writer(csvfile)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response_text.splitlines():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\richard.c.ferrer\\Agents\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'C:/Users/richard.c.ferrer/Agents/cpu_models.csv'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "from vertexai import init\n",
    "from vertexai.generative_models import GenerativeModel, Part, GenerationConfig\n",
    "\n",
    "# Start timer\n",
    "st = time.time()\n",
    "\n",
    "# Initialize Vertex AI\n",
    "init(project=\"cjnyasg-customer360\", location=\"us-central1\")\n",
    "\n",
    "# Initialize model\n",
    "model = GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "\n",
    "# Prompt: request CSV format only\n",
    "prompt = (\n",
    "    \"Generate a CSV with two columns: AMD Ryzen and Intel. \"\n",
    "    \"Each column should contain 5 current desktop CPU models. \"\n",
    "    \"Output only the CSV content, no explanation.\"\n",
    ")\n",
    "\n",
    "# Send prompt\n",
    "input_parts = [Part.from_text(prompt)]\n",
    "generation_config = GenerationConfig(temperature=0, max_output_tokens=8192)\n",
    "response = model.generate_content(contents=input_parts, generation_config=generation_config)\n",
    "response_text = response.text.strip().replace(\"```csv\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "# Print response (for debugging or display)\n",
    "print(response_text)\n",
    "\n",
    "# Save to CSV file\n",
    "csv_filename = \"C:/Users/richard.c.ferrer/Agents/cpu_models.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for line in response_text.splitlines():\n",
    "        row = [cell.strip() for cell in line.split(\",\")]\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"\\nCSV saved as: {csv_filename}\")\n",
    "print(\"Time elapsed:\", time.time() - st)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
